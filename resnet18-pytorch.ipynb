{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agriculture', 'cultivation', 'partly_cloudy', 'primary']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet18 = models.resnet18()\n",
    "\n",
    "#Categories\n",
    "classes=['agriculture','artisinal_mine','bare_ground','blooming','blow_down','clear',\n",
    "'cloudy','conventional_mine','cultivation','habitation','haze',\n",
    "'partly_cloudy','primary','road','selective_logging','slash_burn','water']\n",
    "\n",
    "#Classess and functions to modify layers of imported Resnet18 model\n",
    "class Flatten(nn.Module):\n",
    "    \"Flatten `x` to a single dimension, often used at the end of a model. `full` for rank-1 tensor\"\n",
    "    def __init__(self, full:bool=False):\n",
    "        super().__init__()\n",
    "        self.full = full\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1) if self.full else x.view(x.size(0), -1)\n",
    "\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "\tdef __init__(self, sz=None):\n",
    "\t\tsuper().__init__()\n",
    "\t\tsz = sz or (1)\n",
    "\t\tself.ap = nn.AdaptiveAvgPool2d(sz)\n",
    "\t\tself.mp = nn.AdaptiveMaxPool2d(sz)\n",
    "\n",
    "\tdef forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "    \n",
    "def myhead(nf, nc):\n",
    "    return \\\n",
    "    nn.Sequential(        # the dropout is needed otherwise you cannot load the weights\n",
    "            AdaptiveConcatPool2d(),\n",
    "            Flatten(full=False),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(1024, 512, bias = False),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, nc,bias = False),\n",
    "        )\n",
    "\n",
    "#Modifying layers of imported Resnet18 architecture\n",
    "my_model=models.resnet18() \n",
    "modules=list(my_model.children())\n",
    "modules.pop(-1) \n",
    "modules.pop(-1) \n",
    "temp=nn.Sequential(nn.Sequential(*modules))\n",
    "tempchildren=list(temp.children()) \n",
    "tempchildren.append(myhead(512,17))\n",
    "my_r18=nn.Sequential(*tempchildren)\n",
    "\n",
    "#Preparing model for inference \n",
    "model=my_r18\n",
    "weighties = torch.load('/Users/jib/Documents/models/fastai-rn18.pth',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(weighties['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "## Inference with single image\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "#Change the path to where your test images are located!\n",
    "imgplanet = Image.open(\"/Users/jib/Downloads/test-jpg/test_40478.jpg\").convert('RGB')\n",
    "imgplanet\n",
    "\n",
    "#Preprocessing image\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(128),\n",
    "        transforms.CenterCrop(128),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n",
    "\n",
    "#Converting image to tensor\n",
    "imgplanet_preprocessed = preprocess(imgplanet)\n",
    "imgplanet_tensor = torch.unsqueeze(imgplanet_preprocessed, 0)\n",
    "tensor_list= model.forward(imgplanet_tensor)\n",
    "\n",
    "#Prediction\n",
    "tensor_list.tolist()\n",
    "tensor_list.tolist()[0]\n",
    "tensor_tolist = tensor_list.tolist()[0]\n",
    "indx = [i for i in range(len(tensor_tolist)) if tensor_tolist[i]>0]\n",
    "print([classes[i] for i in indx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgplanet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
